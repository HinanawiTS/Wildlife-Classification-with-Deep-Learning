{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf9da16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57063797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Add official website of pytorch\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import torch.nn.functional as F  # useful stateless functions\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "USE_GPU = True\n",
    "num_class = 100\n",
    "dtype = torch.float32 # we will be using float throughout this tutorial\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# Constant to control how frequently we print train loss\n",
    "print_every = 100\n",
    "\n",
    "print('using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "597ad814",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(x):\n",
    "    N = x.shape[0] # read in N, C, H, W\n",
    "    return x.view(N, -1)  # \"flatten\" the C * H * W values into a single vector per image\n",
    "\n",
    "class ResNetBatch(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channel, num_classes):\n",
    "        super(ResNetBatch, self).__init__()\n",
    "        \n",
    "        self.conv_1 = nn.Conv2d(in_channel, 64, (7, 7), stride = 2, padding = 3)\n",
    "        nn.init.kaiming_normal_(self.conv_1.weight)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace = True)\n",
    "        self.maxpool = nn.MaxPool2d(3, stride = 2, padding = 1)\n",
    "        \n",
    "        self.residual_1 = nn.Conv2d(64, 64, kernel_size = 1)\n",
    "        \n",
    "        self.bn2_1 = nn.BatchNorm2d(64)\n",
    "        self.bn2_2 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.conv_2 = nn.Conv2d(64, 64, (3, 3), padding = 1)\n",
    "        nn.init.kaiming_normal_(self.conv_2.weight)\n",
    "        \n",
    "        self.residual_2 = nn.Conv2d(64, 128, kernel_size = 1)\n",
    "        \n",
    "        self.conv_3_1 = nn.Conv2d(64, 128, (3, 3), padding = 1)\n",
    "        nn.init.kaiming_normal_(self.conv_3_1.weight)\n",
    "        \n",
    "        self.conv_3_2 = nn.Conv2d(128, 128, (3, 3), padding = 1)\n",
    "        nn.init.kaiming_normal_(self.conv_3_2.weight)\n",
    "        \n",
    "        self.bn3_1 = nn.BatchNorm2d(128)\n",
    "        self.bn3_2 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        self.residual_3 = nn.Conv2d(128, 256, kernel_size = 1)\n",
    "        \n",
    "        self.conv_4_1 = nn.Conv2d(128, 256, (3, 3), padding = 1)\n",
    "        nn.init.kaiming_normal_(self.conv_4_1.weight)\n",
    "        \n",
    "        self.conv_4_2 = nn.Conv2d(256, 256, (3, 3), padding = 1)\n",
    "        nn.init.kaiming_normal_(self.conv_4_2.weight)\n",
    "        \n",
    "        self.bn4_1 = nn.BatchNorm2d(256)\n",
    "        self.bn4_2 = nn.BatchNorm2d(256)\n",
    "        \n",
    "        self.residual_4 = nn.Conv2d(256, 512, kernel_size = 1, stride = 2)\n",
    "        \n",
    "        self.conv_5_1 = nn.Conv2d(256, 512, (3, 3), stride = 2, padding = 1)\n",
    "        nn.init.kaiming_normal_(self.conv_5_1.weight)\n",
    "        \n",
    "        self.conv_5_2 = nn.Conv2d(512, 512, (3, 3), padding = 1)\n",
    "        nn.init.kaiming_normal_(self.conv_5_2.weight)\n",
    "        \n",
    "        self.bn5_1 = nn.BatchNorm2d(512)\n",
    "        self.bn5_2 = nn.BatchNorm2d(512)\n",
    "        \n",
    "        self.avgpool = nn.AvgPool2d(3 + 1)\n",
    "        self.fs = nn.Linear(18432, num_classes)\n",
    "        \n",
    "    def forward(self, x): \n",
    "        x = self.relu(self.bn1(self.conv_1(x)))\n",
    "        x = self.maxpool(x)\n",
    "        r1 = self.residual_1(x)\n",
    "        \n",
    "        x = self.relu(self.bn2_1(self.conv_2(x)))\n",
    "        x = self.relu(self.bn2_2(self.conv_2(x)))\n",
    "        r2 = x + r1\n",
    "        \n",
    "        x = self.relu(self.bn3_1(self.conv_3_1(r2)))\n",
    "        x = self.relu(self.bn3_2(self.conv_3_2(x)))\n",
    "        \n",
    "        r3 = x + self.residual_2(r2)\n",
    "        \n",
    "        x = self.relu(self.bn4_1(self.conv_4_1(x)))\n",
    "        x = self.relu(self.bn4_2(self.conv_4_2(x)))\n",
    "        r4 = x + self.residual_3(r3)\n",
    "        \n",
    "        x = self.relu(self.bn5_1(self.conv_5_1(x)))\n",
    "        x = self.relu(self.bn5_2(self.conv_5_2(x)))\n",
    "        r5 = x + self.residual_4(r4)\n",
    "        \n",
    "        x = self.avgpool(r5)\n",
    "        x = flatten(x)\n",
    "        x = self.fs(x)\n",
    "        \n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0a1a7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy_part34(loader, model):\n",
    "    \n",
    "    print('Checking accuracy on validation set')\n",
    "    \n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            scores = model(x)\n",
    "            _, preds = scores.max(1)\n",
    "            num_correct += (preds == y).sum()\n",
    "            num_samples += preds.size(0)\n",
    "        acc = float(num_correct) / num_samples\n",
    "        print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddd5bd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_part34(model, optimizer, epochs=1):\n",
    "    \"\"\"\n",
    "    Train a model on CIFAR-10 using the PyTorch Module API.\n",
    "    \n",
    "    Inputs:\n",
    "    - model: A PyTorch Module giving the model to train.\n",
    "    - optimizer: An Optimizer object we will use to train the model\n",
    "    - epochs: (Optional) A Python integer giving the number of epochs to train for\n",
    "    \n",
    "    Returns: Nothing, but prints model accuracies during training.\n",
    "    \"\"\"\n",
    "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
    "    for e in range(epochs):\n",
    "        for t, (x, y) in enumerate(loader_train):\n",
    "            model.train()  # put model to training mode\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "\n",
    "            scores = model(x)\n",
    "            loss = F.cross_entropy(scores, y)\n",
    "\n",
    "            # Zero out all of the gradients for the variables which the optimizer\n",
    "            # will update.\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # This is the backwards pass: compute the gradient of the loss with\n",
    "            # respect to each  parameter of the model.\n",
    "            loss.backward()\n",
    "\n",
    "            # Actually update the parameters of the model using the gradients\n",
    "            # computed by the backwards pass.\n",
    "            optimizer.step()\n",
    "\n",
    "            if t % print_every == 0:\n",
    "                print('Epoch %d, Iteration %d, loss = %.4f' % (e, t, loss.item()))\n",
    "                check_accuracy_part34(loader_val, model)\n",
    "                print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c31d5b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision import datasets, transforms, models \n",
    "\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "batch_size = 16\n",
    "dataroot = \"C:/Users/HinanawiTS/Documents/GitHub/ECE228-project/processed\"\n",
    "dataset = ImageFolder(root = dataroot, transform = transforms.Compose([transforms.ToTensor()]))\n",
    "train_ratio = 0.7\n",
    "trainlen = int(len(dataset)*train_ratio)\n",
    "vallen = len(dataset)-trainlen\n",
    "train, val = random_split(dataset, [trainlen, vallen])\n",
    "loader_train = DataLoader(train, batch_size = batch_size, num_workers = 0, pin_memory = True)\n",
    "loader_val = DataLoader(val, batch_size = batch_size, num_workers = 0, pin_memory = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e62015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Iteration 0, loss = 4.5370\n",
      "Checking accuracy on validation set\n",
      "Got 10 / 971 correct (1.03)\n",
      "\n",
      "Epoch 0, Iteration 100, loss = 3.5040\n",
      "Checking accuracy on validation set\n",
      "Got 103 / 971 correct (10.61)\n",
      "\n",
      "Epoch 1, Iteration 0, loss = 2.5702\n",
      "Checking accuracy on validation set\n",
      "Got 152 / 971 correct (15.65)\n",
      "\n",
      "Epoch 1, Iteration 100, loss = 1.8223\n",
      "Checking accuracy on validation set\n",
      "Got 156 / 971 correct (16.07)\n",
      "\n",
      "Epoch 2, Iteration 0, loss = 1.6527\n",
      "Checking accuracy on validation set\n",
      "Got 190 / 971 correct (19.57)\n",
      "\n",
      "Epoch 2, Iteration 100, loss = 0.8483\n",
      "Checking accuracy on validation set\n",
      "Got 184 / 971 correct (18.95)\n",
      "\n",
      "Epoch 3, Iteration 0, loss = 0.8410\n",
      "Checking accuracy on validation set\n",
      "Got 191 / 971 correct (19.67)\n",
      "\n",
      "Epoch 3, Iteration 100, loss = 0.3791\n",
      "Checking accuracy on validation set\n",
      "Got 185 / 971 correct (19.05)\n",
      "\n",
      "Epoch 4, Iteration 0, loss = 0.3748\n",
      "Checking accuracy on validation set\n",
      "Got 185 / 971 correct (19.05)\n",
      "\n",
      "Epoch 4, Iteration 100, loss = 0.2176\n",
      "Checking accuracy on validation set\n",
      "Got 201 / 971 correct (20.70)\n",
      "\n",
      "Epoch 5, Iteration 0, loss = 0.2332\n",
      "Checking accuracy on validation set\n",
      "Got 194 / 971 correct (19.98)\n",
      "\n",
      "Epoch 5, Iteration 100, loss = 0.0813\n",
      "Checking accuracy on validation set\n",
      "Got 217 / 971 correct (22.35)\n",
      "\n",
      "Epoch 6, Iteration 0, loss = 0.1088\n",
      "Checking accuracy on validation set\n",
      "Got 207 / 971 correct (21.32)\n",
      "\n",
      "Epoch 6, Iteration 100, loss = 0.1275\n",
      "Checking accuracy on validation set\n",
      "Got 223 / 971 correct (22.97)\n",
      "\n",
      "Epoch 7, Iteration 0, loss = 0.0536\n",
      "Checking accuracy on validation set\n",
      "Got 224 / 971 correct (23.07)\n",
      "\n",
      "Epoch 7, Iteration 100, loss = 0.0343\n",
      "Checking accuracy on validation set\n",
      "Got 221 / 971 correct (22.76)\n",
      "\n",
      "Epoch 8, Iteration 0, loss = 0.0408\n",
      "Checking accuracy on validation set\n",
      "Got 227 / 971 correct (23.38)\n",
      "\n",
      "Epoch 8, Iteration 100, loss = 0.0202\n",
      "Checking accuracy on validation set\n",
      "Got 233 / 971 correct (24.00)\n",
      "\n",
      "Epoch 9, Iteration 0, loss = 0.0255\n",
      "Checking accuracy on validation set\n",
      "Got 229 / 971 correct (23.58)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = ResNetBatch(3, 90)\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.0001)\n",
    "train_part34(model, optimizer, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a460d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from os import listdir\n",
    "import os\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "def csg(img, dim):\n",
    "    width, height = img.shape[1], img.shape[0]\n",
    "\n",
    "\n",
    "    crop_width = dim[0] if dim[0]<img.shape[1] else img.shape[1]\n",
    "    crop_height = dim[1] if dim[1]<img.shape[0] else img.shape[0] \n",
    "    mid_x, mid_y = int(width/2), int(height/2)\n",
    "    cw2, ch2 = int(crop_width/2), int(crop_height/2) \n",
    "    crop_img = img[mid_y-ch2:mid_y+ch2, mid_x-cw2:mid_x+cw2]\n",
    "    return crop_img\n",
    "\n",
    "i = 0\n",
    "t = \"animals/\"\n",
    "for an in listdir(t):\n",
    "    th = t + an + \"/\"\n",
    "    os.mkdir(\"processed/\" + an)\n",
    "    for fs in listdir(th): \n",
    "    \n",
    "        i = i + 1\n",
    "    \n",
    "        print(th + fs)\n",
    "    \n",
    "        gna = cv2.imread(th + fs, cv2.IMREAD_UNCHANGED)\n",
    "        if (gna.shape[0] > 200) and (gna.shape[1] > 200): \n",
    "\n",
    "            img = cv2.imread(th + fs, cv2.IMREAD_UNCHANGED)\n",
    "            width = 200\n",
    "\n",
    "            height = 200\n",
    "            dim = (width, height)\n",
    "  \n",
    "            # resize image\n",
    "            if gna.shape[0] < gna.shape[1]: \n",
    "                resiz = csg(img, (gna.shape[0], gna.shape[0]))\n",
    "            else: \n",
    "            \n",
    "                resiz = csg(img, (gna.shape[1], gna.shape[1]))\n",
    "    \n",
    "            resiz = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
    "            print(\"processed/\" + an + \"/\" + str(i) + \".jpg\")\n",
    "            cv2.imwrite(\"processed/\" + an + \"/\" + str(i) + \".jpg\", resiz)\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
